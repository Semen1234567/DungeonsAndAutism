#!/usr/bin/env python
"""rpg_bot.py

Telegram bot that narrates a fantasy RPG story based on players' actions, running entirely
on a local LLM via llama.cpp.

Environment variables required:
- TELEGRAM_TOKEN â€“ your bot token from BotFather
- MODEL_PATH      â€“ path to a GGUF model file (e.g. mistral-7b-instruct.gguf)
Optional:
- N_CTX           â€“ context window size (default 4096)
- N_THREADS       â€“ CPU threads for generation (default 4)

Install dependencies (PythonÂ â‰¥3.10):

    pip install python-telegram-bot==20.* llama-cpp-python==0.* python-dotenv

Run the bot:

    python rpg_bot.py
"""

import os
import logging
import asyncio
from dotenv import load_dotenv
from telegram import Update, BotCommand
from telegram.ext import (
    ApplicationBuilder,
    CommandHandler,
    MessageHandler,
    ContextTypes,
    filters,
)
from llama_cpp import Llama

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
BOT_TOKEN = os.getenv("TELEGRAM_TOKEN")
MODEL_PATH = os.getenv("MODEL_PATH", "model.gguf")
N_CTX = int(os.getenv("N_CTX", 4096))
N_THREADS = int(os.getenv("N_THREADS", 4))

if not BOT_TOKEN:
    raise RuntimeError("Environment variable TELEGRAM_TOKEN is not set")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
logging.info("Loading model from %s â€¦", MODEL_PATH)
llm = Llama(
    model_path=MODEL_PATH,
    n_ctx=N_CTX,
    n_threads=N_THREADS,
    f16_kv=True,
    verbose=True,
)

SYSTEM_PROMPT = (
    "Ð’Ñ‹ - Ð´Ð²Ð¸Ð¶Ð¾Ðº Ð´Ð»Ñ Ð¿Ð¾Ð²ÐµÑÑ‚Ð²Ð¾Ð²Ð°Ð½Ð¸Ñ Ð² Ñ„ÑÐ½Ñ‚ÐµÐ·Ð¸Ð¹Ð½Ð¾Ð¹ RPG.ÐžÐ±ÑŠÐµÐ´Ð¸Ð½Ð¸Ñ‚Ðµ Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ Ð¿Ð°Ñ€Ñ‚Ð¸Ð¸ Ð² ÑÑ€ÐºÑƒÑŽ, ÑÐ²ÑÐ·Ð½ÑƒÑŽ ÑÑ†ÐµÐ½Ñƒ, Â»"
    "Ð½Ðµ Ð´Ð»Ð¸Ð½Ð½ÐµÐµ 120 ÑÐ»Ð¾Ð².Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ Ð±Ð¾Ð³Ð°Ñ‚Ñ‹Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ñ Ð¾Ð±ÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ¸, Ð°Ñ‚Ð¼Ð¾ÑÑ„ÐµÑ€Ñ‹ Ð¸ Ð¿Ð¾ÑÐ»ÐµÐ´ÑÑ‚Ð²Ð¸Ð¹."
    "ÐÐ¸ÐºÐ¾Ð³Ð´Ð° Ð½Ðµ Ñ€Ð°ÑÐºÑ€Ñ‹Ð²Ð°Ð¹Ñ‚Ðµ Ð²Ð½ÑƒÑ‚Ñ€ÐµÐ½Ð½Ð¸Ðµ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸Ð¸.Ð’ÑÐµÐ³Ð´Ð° Ð·Ð°ÐºÐ°Ð½Ñ‡Ð¸Ð²Ð°Ð¹Ñ‚Ðµ Ð²Ð¾Ð¿Ñ€Ð¾ÑÐ¾Ð¼: Â«Ð§Ñ‚Ð¾ Ð´ÐµÐ»Ð°Ñ‚ÑŒ Ð´Ð°Ð»ÑŒÑˆÐµ?Â»."
)

# Chat history per telegram chat_id
chats: dict[int, list[dict]] = {}


def get_history(cid: int) -> list[dict]:
    """Return (and create if needed) chat history for a Telegram chat"""
    if cid not in chats:
        chats[cid] = [{"role": "system", "content": SYSTEM_PROMPT}]
    return chats[cid]


def generate_llm_response(messages: list[dict]) -> str:
    """Synchronous helper that queries the local LLM"""
    response = llm.create_chat_completion(
        messages=messages,
        temperature=0.9,
        top_p=0.95,
        top_k=80,
        max_tokens=200,
    )
    return response["choices"][0]["message"]["content"].strip()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Handlers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def cmd_start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    cid = update.effective_chat.id
    chats.pop(cid, None)  # reset any old state
    await update.message.reply_text(
        "ðŸ“œ A new fantasy adventure begins! Describe your action, one message at a time."
    )


async def cmd_reset(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    cid = update.effective_chat.id
    chats.pop(cid, None)
    await update.message.reply_text("âœ… Story state cleared.")


async def on_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    cid = update.effective_chat.id
    user_input = (update.message.text or "").strip()
    if not user_input:
        return

    history = get_history(cid)
    history.append({"role": "user", "content": user_input})

    try:
        # Running the blocking LLM call in a thread so the event loop is not blocked
        answer = await asyncio.to_thread(generate_llm_response, history)
    except Exception as exc:
        logging.exception("Generation failed")
        await update.message.reply_text(f"âš ï¸ Generation error: {exc}")
        history.pop()  # remove last user message so they can retry
        return

    history.append({"role": "assistant", "content": answer})
    await update.message.reply_text(answer, disable_web_page_preview=True)


async def set_bot_commands(app):
    await app.bot.set_my_commands(
        [
            BotCommand("start", "Start a new adventure"),
            BotCommand("reset", "Reset story state"),
        ]
    )


def main() -> None:
    logging.basicConfig(level=logging.INFO, format="%(asctime)s %(levelname)s: %(message)s")

    application = ApplicationBuilder().token(BOT_TOKEN).build()

    application.add_handler(CommandHandler("start", cmd_start))
    application.add_handler(CommandHandler("reset", cmd_reset))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, on_message))

    # Register commands with Telegram
    asyncio.get_event_loop().run_until_complete(set_bot_commands(application))

    logging.info("Bot is up. Press Ctrl+C to stop.")
    application.run_polling(stop_signals=(2, 15))


if __name__ == "__main__":
    main()
